
* compile
  need to add
  : -lpthread
  when compile.

* concept
  join
  detach

* pthread
** pthread_cancel
   defer it until it reaches a cancellation point. \\
   cause dead lock/memory leak if cancel unsafely!
   
   : pthread_testcancel()
   : boost::this_thread::interruption_point()
   
polling ?

* boost
  use exception
  it'll call destructor automatically

* async & future
  #+BEGIN_SRC C++
  #include "future"
  int func();
  // try start func() asynchronously in the background (now or later or never)
  // assign the result to the object of class std::future
  std::future<int> result(std::async(func());
  // ^ auto works as well
  // do something else
  result.get();
  #+END_SRC
  use future for two reasons:
  - it allows access to the "future" outcome *(store state/result)* of
    the functionality passed to async(). The outcome might be either a
    return value or an exception.
    : std::future<void> for returns nothing
  - async() may not start ever (if no more separated thread is
    availble, it will defer), use future to force a start.
  - async() is a function and it returns future

  To have better effect, maximize the distance between calling
  async() and calling get()

  | operaton         | effect                                                                                              |
  |------------------+-----------------------------------------------------------------------------------------------------|
  | future f(rv)     | move constructor, *gets the state* (not copy) of rv and *invalidates* the state of rv               |
  | f = rv           | move assignments, destroys the old state of f, gets the state of rv and invalidates the state of rv |
  | f.valid()        | yields true if f has a valid state, so you can call the following member functions                  |
  | f.get()          | blocks until the background operation is done                                                       |
  | f.wait()         | same as get(), block but not return result. Call get() after wait()                                 |
  | f.wait_for(dur)  |                                                                                                     |
  | f.wait_until(tp) |                                                                                                     |
  | f.share()        | yields a shared_future with the current state and invalidates the state of f                        |
  
  

** launch policy
   To force async() to not defer the passed functionality, explicitly
   passing a /launch policy/.
   #+BEGIN_SRC C++
   // force func() to start asynchronously now or throw std::system_error
   // if it's not possible to call here
   std::future<long> result = std::async(std::launch::async, func);
   // std::launch::defered
   #+END_SRC
   In this case, no need to call get() anymore. If the *lifetime* of
   the returned future ends, the program will *wait* for func() to
   finish.

** deal with exceptions
   If exception is not caught in the thread, future will keep this
   state until get() is called, and propagated to main.

** waiting and polling
   You can can *only call get() once*. After get(), the future is in an
   invalid state, which can be checke only by calling valid() for the
   future.

   Below are callable more than once
*** wait()
    wait() forces the start of a thread a future represents and *waits*
    (block) for the termination.
    Looks like get(), but can be called more than once, and don't
    return result. Call get() after wait().
*** wait_for(), wait_until()
    do /not/ force the thread to get started if it hasn't started yet.
    #+BEGIN_SRC CPP
    std::future<...> f(std::async(func));
    ...
    f.wait_for(std::chrono::seconds(10));
    f.wait_until(std::system_clock()::now() + std::chrono::minutes(1));
    #+END_SRC
    wait_for, wait_until return one of the following:
    | std::future_status::deferred | if async() deferred the operation and no calls to wait() or get() have yet forced it to start(both function return immediately in this case) |
    | std::future_status::timeout  | the waiting expired due to the passing timeout                                                                                               |
    | std::future_status::ready    | the operation is finished                                                                                                                    |
    
** shared future
   future's get() can only be called once. With situation when
   multiple threads process the outcome, use shared_future. Here,
   multiple get() calls are possible and *yield the same result or
   throw the same exception*.
   : std::shared_future<int> f = std::async(func);
   : auto f = std::async(func).share();
   | future                   | shared_future                    |
   |--------------------------+----------------------------------|
   | T future<T>::get()       | const T& shared_future<T>::get() |
   | T& future<T&>::get()     | T& shared_future<T&>::get()      |
   | void future<void>::get() | void shared_future<void>::get()  |
   "The *single-use* value get() is *move optimized*, the *const reference*
   get() is *access optimized*."
   The multiple shared future objects share the same /shared
   state/. Though possible, it's risky to share one future object (by
   reference).

* thread
  As for async(), you can pass anything that's a /callable object/
  (function, member function, function object, lambda) together with
  possible additional arguments. It's recommended to pass all objects
  by value so that the thread uses only /local copies/.

  Thread is low-level interface, things it does not provides compared
  to async():
  - doesn't have a launch policy. Thread *always tries to start* the
    passed functionality in a new thread. If it isn't possible, it
    throws a std::system_error with the error code
    resource_unavailble_try_again.
  - *no interfaces to process the result or outcome of the thread*. The
    only thing you can get is a unique thread ID.
  - if an exception occurs that is not caught inside the thread, the
    program immediately aborts, calling std::terminate(). (won't
    propagate the exception to the caller?) \\
    : exception_ptrs ?
  - need to call join()(wait for teh end), detach()(let it run in the
    background without any control). If you don't do this before the
    lifetime of the thread objects ends or a move assignment to it
    happens, the program aborts, calling std::terminate()
  - if you let the thread run in the background and main() ends (return
    or exit), all threads are terminated abruptly.
    #+BEGIN_QUOTE
    To allow other threads to continue execution, the main thread
    should terminate by calling pthread_exit() rather than exit(3).
    #+END_QUOTE
  - a static member function to query a hint for the possible number
    of parallel threads:
    : unsigned int std::thread::hardware_concurrency()
    just a hint and does not guarentee to be exact

    | operation                    | effect                                |
    |------------------------------+---------------------------------------|
    | this_thread::get_id()        |                                       |
    | this_thread::sleep_for(dur)  |                                       |
    | this_thread::sleep_until(tp) |                                       |
    | this_thread::yield()         | hint to reschedule to the next thread |

    this_thread::yield() is provided to give a hint to the system
    that it's usefule to *give up the remainder of the current
    thread's time slice* so that the runtime environment can
    reschedule to allow other threads to run. One typical example is
    to give up control when you wait or "poll" for another thread or
    an atomic flag to be set by another thread:
    #+BEGIN_SRC c++
    while(!readyFlag) {  // loop until data is ready
      std::this_thread::yield();
    }
    #+END_SRC
    
** Thread IDs
   - Thread id of a joinable thread (thread with associated task) are
     unique. For those without associated task, its id is same as
     std::thread::id() (unique as well).
     : std::thread t;
     : assert(t.get_id() == std::thread::id());
     : std::this_thread::get_id()
   - Note! For those nojoinable(finished task, or detach), cout
     get_id() will get the output:
     : thread::id of a non-executing thread
     *So, you can only call get_id() before join() or detach().*
   - If a thread has finished its task, its id might be assigned to
     other thread.
   - the only way to identify a thread, such as a master thread, is
     to compare it to its saved ID when it was started
   - if a thread object is joinable, no other thread object can be
     assigned to it

** beware of detached threads
   - make sure that a detached thread does not access any object s
      after their lifetime has ended. Passing arguments by value is
      strongly recommended.
   - if a detached thread use a global/static object, do:
     - ensure these global/static objects are not destroyed before
       all detached threads finished accessing them. One approach to
       ensure is to use *condition variables* which the detached
       threads use to signal that they have finished.
     - end the program by calling quick_exit(), which won't call the
       destructors for global and static objects.
     - std::cin/cout/cerr and the other *global stream objects*
       according to the standard "are not destroyed during program
       execution," access to these objects in detached threads
       should introduce no undefined behavior.

* promise
   To retrieve result from thread, you can pass return arguments by
   reference. Another general mechanism is provided to pass result
   values and exceptions as *outcomes of a thread*: class
   std::promise. A promise object is the counterpart of a /future/
   object. Both are able to temporarily hold a /shared state/,
   representing a (result) value or an exception. While the future
   object allows you to *retrieve the data* (using get()), the promise
   object enables you to *provide the data* (by using set...()).
   - The promise *internally creates a /shared state/*, which can be
     used to store a value of the corresponding type or an exception,
     and can be used in a future object to retrieve this data as the
     outcome of the thread.
   - copying is not possible for promise, use std::ref()
   - catch exception in thread and set it to promise. Then this
     exception won't throw right now, can be catched later when future
     object call get(). Nice!
   - once set_value/exception, the /shared state/ is /ready/, and
     get() will return. There are set_value_at_thread_exit(val),
     set_exception_at_thread_exit(e), which make the /state ready/ at
     the end of the current thread (or throws std::future_error).
   - you can call get_future() only once. A second call throws a
     std::future:error with error code std::future_errc::future_already_retrieved.
   - if no /shared state/ is associated, a std::future_error with the
     error code std::future_errc::no_state might be thrown.
   - Can a promise shared by several thread? It seems impossible
     since get_future can only be called once!

   | operation                         | effect                                                                                                   |
   |-----------------------------------+----------------------------------------------------------------------------------------------------------|
   | promise p                         |                                                                                                          |
   | promise p(rv)                     | move constructor; gets the state of /rv/ and removes the /shared state/ from rv                          |
   | p = rv                            | move assignment; if p is not /ready/, stores a std::future_error exception with condition broken_promise |
   | p.get_future()                    | yields a future object to retrieve the shared state (outcome of a thread)                                |
   | p.set_value(val)                  | set val as (return) value and makes the state /ready/ (or throws std::future_error)                      |
   | p.set_value_at_thread_exit(val)   |                                                                                                          |
   | p.set_exception(e)                |                                                                                                          |
   | p.set_exception_at_thread_exit(e) |                                                                                                          |

* packaged_task
  also defined in future, *holds both the functionality to perform and
  its possible outcome* (the so-called shared state of the functionality)
  #+BEGIN_SRC C++
  double compute(int x, int y);
  std::packaged_task<double(int, int)> task(compute);
  std::future<double> f = task.get_future();
  task(7, 5);  // start the task (typically in a separate thread)
  double res = f.get();
  #+END_SRC
  - try to call the task or get_future() if no state is available
    throws a std::future_error with error code std::future_errc::no_state
  - calling get_future() a second time throws an exception of type
    std::future_error with the error code std::future_errc:future_already_retrieved
  - calling the task a second time throws a std::future_error with
    error code std::future_errc::promise_already_satisfied

   | operation                          | effect                                                                                                        |
   |------------------------------------+---------------------------------------------------------------------------------------------------------------|
   | packaged_task pt(f)                |                                                                                                               |
   | packaged_task pt(rv)               | move constructor, moves the packaged task rv (task and state) to pt (rv has no shared state afterwared)       |
   | pt = rv                            | move assignment                                                                                               |
   | pt.valid()                         | yields true if pt has a shared state                                                                          |
   | pt.get_future()                    |                                                                                                               |
   | pt(args)                           | calls the task (with optional arguments) and makes the shared state ready. This should be called before get() |
   | pt.make_ready_at_thread_exit(args) | calls the task and at thread exit makes the shared state ready                                                |
   | pt.reset()                         | creates a new shared state for pt (might make the old shared state ready)                                     |

* mutex
  #+BEGIN_SRC C++
  #include "mutex"
  std::mutex a_mutex;
  a_mutex.lock();
  // do something
  a_mutex.unlock();
  #+END_SRC
** lock guard
   if an exception occur, which ends an exclusive access, a resource
   might become locked forever
   - use the RAII principle (/Resouce Acquisition Is
      Initialization/), whereby the constructor acquires a resource so
      that the destructor, which is always called when an exception
      causes the end of the lifetime, release the resource automatically
   - for this purpose, the C++ standard library provides class std::lock_guard
      #+BEGIN_SRC C++
      {
        std::lock_guard<std::mutex> lg(a_mutex);  // lock and automatically unlock
        // do something
      }  // ensures that lock gets released here
      #+END_SRC
   - *Insert explicit braces* so that lock gets released before
      futher statements are processed.

** recursive mutex
   #+BEGIN_SRC C++
   class DatabaseAccess {
   private:
     std::recursive_mutex db_mutex;
     ...  // state of database access
   public:
     void create_table() {
       std::lock_guard<std::recursive_mutex> lg(db_mutex);
       ...
     }
     void insert_data() {
       std::lock_guard<std::recursive_mutex> lg(db_mutex);
       ...
     }
     void create_table_and_insert_data() {
       std::lock_guard<std::recursive_mutex> lg(db_mutex);
       create_table();  // using recursive_mutex is ok, no deadlock
        	        // however, using mutex is ERROR
       ...
     }
   };
   #+END_SRC
** tried mutex

   mutex provides a try_lock() member function that /tries/ to
   acquire a lock. If it succeeds, it returns true; if not, false
   (*not block*).
   #+BEGIN_SRC C++
   std::mutex m;
   // try to acquire a lock and do other stuff while this isn't possible
   while (m.try_lock() == false) {
     do_some_other_stuff();
   }
   // since lock has been acquire above, don't need lock_guard to acqiure the 
   // lock, add std::adopt_lock so that any exit from the current scope unlocks
   // the mutex
   std::lock_guard<std::mutex> lg(m, std::adopt_lock);
   #+END_SRC

** timed mutex
   #+BEGIN_SRC C++
   std::timed_mutex m;
   // try for one second to acquire a lock
   if (m.try_lock_for(std::chrono::seconds(1))) {
     std::lock_guard<std::timed_mutex> lg(m, std::adopt_lock);
     ...
   } else {
     could_not_get_the_lock();
   }
   #+END_SRC
   try_lock_for, try_lock_until \\
   std::timed_mutex, std::recursived_timed_mutex

** multipled locks
   Locking more than one mutex at a time might be complicated and
   risky: you might get the first but not the second lock, or
   deadlock situations may occur if you lock the same locks in a
   different order.
   #+BEGIN_SRC C++
   std::mutex m1, m2;
   {
     std::lock(m1, m2);  // lock both mutex (or none if not possible)
     std::lock_guard<std::mutex> lock_m1(m1, std::adopt_lock);
     std::lock_guard<std::mutex> lock_m2(m2, std::adopt_lock);
   }  // automatically unlock all mutexes
   #+END_SRC
   - std::lock() locks all mutexes passed as arguments *blocking* until
     all mutexes are locked or until an exception is thrown. In the
     latter case, it *unlocks* mutexes already successfully locked.
   - After successful locking, use lock_guard with std::adopt_lock
   - std::lock() provides a *deadlock-avoidance* mechanism, which,
     however, means that *the order of locking inside a multiple lock
     is undefined*
   #+BEGIN_SRC C++
   int idx = std::try_lock(m1, m2);  // try to lock both mutexes
   if (idx < 0) {  // both locks succeeded
     std::lock_guard<std::mutex> lock_m1(m1, std::adopt_lock);  
     std::lock_guard<std::mutex> lock_m2(m2, std::adopt_lock);
     ...
   } else {
     // idx has zero-based index of first failed lock
     std::cerr << "could not lock mutex m" << idx+1 << std::endl;
   }
   #+END_SRC
   - /try/ to acqurie multiple locks *without blocking* if not all
     locks are available.
   - std::try_lock() *returns -1* if all locks were possible. If not,
     the return value is the zero-based index of the first failed
     lock. In that case, all succeeded locks are unlocked again.
   - try_lock does not provide a deadlock-avoidance
     mechanism. Instead, it guarantees that the locks are tried in
     the order of the passed arguments.
** unique_lock
   - More flexible, same interface as clock_guard<>, plus the ability
     to program explicitly *when and how to* lock or unlock its mutex.
   - may or may not have a mutex locked (/owning a mutex/). This
     differs from a *lock_guard<>, which always has an object locked
     throughout its lifetime*.
   - When the mutex is locked at destruction time, the destructor
     automatically calls unlock() for it.
   #+BEGIN_SRC C++
   std::unique_lock<std::mutex> lock(mutex, std::try_to_lock); 
   ...
   if (lock) { // if lock was successful
     ...
   }
   
   // try to lock for a specific duration
   std::unique_lock<std::timed_mutex> lock(mutex, std::chrono::seconds(1));
   ...
   
   // initialize the lock without locking the mutex(yet)
   std::unique_lock<std::mutex> lock(mutex, std::defer_lock);
   ...
   lock.lock();  // or (timed) try_lock()
   
   // can create multiple locks and lock them later
   std::mutex m1, m2;
   std::unique_lock<std::mutex> lock_m1(m1, std::defer_lock);
   std::unique_lock<std::mutex> lock_m2(m2, std::defer_lock);
   ...
   std::lock(m1, m2);  // lock both mutexes (or non if not possible)
   #+END_SRC
   | operation                    | effect                                                                        |
   |------------------------------+-------------------------------------------------------------------------------|
   | unique_lock l                | creates a lock not associated with a mutex                                    |
   | unique_lock l(m)             | creates a lock guard for the mutex m and locks it                             |
   | unique_lock l(m, adopt_lock) | creates a lock guard for the already locked mutex m                           |
   | unique_lock l(m, defer_lock) | creates a lock guard for the mutex m without locking it                       |
   | unique_lock l(m, try_lock)   | creates a lock guard for the mutex m and tries to locks it                    |
   | unique_lock l(m, dur)        | creates a lock guard for the mutex m and tries to locks it for a duration dru |
   | unique_lock l(m, tp)         | creates a lock guard for the mutex m and tries to locks it until timepoint tp |
   | unique_lock l(rv)            | move lock state from rv to l (rv has no associated mutex anymore)             |
   | unique_lock l = rv           |                                                                               |
   | l.~unique_lock()             | unlocks the mutex, if any locked, and destroys the lock guard                 |
   | l.mutex()                    | returns a pointer to the associated mutex                                     |
   | l.release()                  | returns a pointer to the associated mutex and releases it                     |
   | l.owns_lock()                | returns true if an associated mutex is locked                                 |
   | l.lock()                     |                                                                               |
   | l.try_lock()                 |                                                                               |
   | l.try_lock_for(dur)          |                                                                               |
   | l.try_lock_until(tp)         |                                                                               |
   | t.unlock()                   |                                                                               |
   
** summary
   - std::mutex is a simple mutex that can be *locked only once by one
     thread at a time*. If it's locked, any other lock() will block
     until mutex is avaible again and try_lock() will fail
   - std::recursive_mutex is a mutex that *allows multiple locks at
     the same time by the same thread*. The typical application of
     such a lock is where functions acquire a lock and internally
     call another function, which also acquires the same lock again
   - lock() might throws a std::system_error
     | operation_not_permitted       | the thread does not have the privilege to perform the operation(when unlock a mutex not belong to it) |
     | resource_deadlock_would_occur | the platform detects that a deadlock would occur                |
     | device_or_resource_busy       | it the mutex is already locked and blocking is not possible     |
   - the behavior of a program is underfined if it unlocks a mutex
     object it doesn't own, destroys a mutex object owned by any
     thread, or if a thread terminates while owning a mutex object
   - std::lock_guard, throughout its lifetime, it's always associated
     with a lock either explicitly requested or adopted at
     construction time
   - std::unique_lock provides a lock guard for a mutex that *does not
     necessarily have be locked(/owned but not lock/)*. 
** call once for multiple threads
   Situation like /lazy initialization/ in a *multithreaded context*,
   where data races might occur if two or more threads check whether
   the initialization didn't happen yet and start the initialization
   then.
   #+BEGIN_SRC C++
   class X {
    private:
     mutable std::once_flag init_data_flag;
     void init_data() const;
    public:
     data get_data() const {
       std::call_once(init_data_flag, &X::init_data, this);
     }
   };
   #+END_SRC


* conditional variable
  The mutex ensures that reads and writes are atomic.
* note
** two situations may lead to one thread occupying cpu
  - std::future_status::deferred
    #+BEGIN_SRC CPP
    // need to judge, otherwise, the while loop may run forever!
    // or use std::launch::async when constructing 
    // if (f.wait_for(std::chrono::seconds(0)) != std::futrue_status::deferred))
    while (f.wait_for(std::chrono::seconds(0)) != std::future_status::ready) {
      // wait
    }
    #+END_SRC
  - std::this_thread::yield() \\
    hint to reschedule to the next thread, give up its time 
** lifetime
   - when parsing reference to thread, make sure the object's lifetime
     is larger than the thread
   - detach thread will go on runing even main exit? Make sure
     global/static object not destruct if they are use in detached thread.
   
  
** sth
   - while async, promise, packaged_task use /shared state/, thread can
     use /shared variales/, and thread use exception_ptr to process
     exception.

** summary
   - with the low-level interface of class thread, we can start a
     thread. To return data, we need shared variables (global or
     static or passed as argument). To return exceptions, we could
     use the type std::exception_ptr, which is returned by
     std::current_exception() and can be processed by
     std::rethrow_exception()
   - the concept of a /shared state/ allow us to deal with return
     values or exceptions in a more convenient way. With the
     low-level interface of a promise, we can create such a /shared
     state/, which we can process by using a future
   - at a higher level, with class packaged_task or async(), the
     /shared state/ automatically created and set with a return
     statement or an uncaught exception.
   - with packaged_task, we can create an object with a shared state
     where *we explicitly have to program when to start the thread*.
   - with std::async(), we *don't have to care when the thread exactly
     gets started*. The only thing we know is that we have to call
     get() when we need the outcome.

