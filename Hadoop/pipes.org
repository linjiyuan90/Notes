
While streamming use stdin/stdout, pipes use *socket* to communicate.

* build
  The library in ${HADOOP_HOME}/c++/Linux-amd64-64/lib may not work!
  Need to build native library.
  : ant -Dcompile.c++=yes example
  doesn't work for me. I follow
  http://guoyunsky.iteye.com/blog/1709654 to build native library.
  
  #+BEGIN_SRC shell
  $ cd src/c++/utils/
  $ ./configure & make install
  $ cd src/c++/pipes/
  $ ./configure & make install
  #+END_SRC
  
  after that, you'll see this generate directories in src/c++/install/
  #+BEGIN_EXAMPLE
  install/
  ├── include
  │   └── hadoop
  │       ├── Pipes.hh
  │       ├── SerialUtils.hh
  │       ├── StringUtils.hh
  │       └── TemplateFactory.hh
  └── lib
      ├── libhadooppipes.a
      └── libhadooputils.a
  #+END_EXAMPLE

  note:
  - if error occures when configure c++/pipes:
    : ./configure: line 302: return: please: numeric argument required
    modify configure according to http://hadoop.illecker.at/?p=206
    #+BEGIN_SRC shell
    # as_fn_set_status STATUS
    # -----------------------
    # Set $? to STATUS, without forking.
    as_fn_set_status ()
    {
    if echo $1 | egrep -q '^[0-9]+$'; then // $1 number check
      return $1
    fi
    } # as_fn_set_status
    # as_fn_exit STATUS
    # -----------------
    # Exit the shell with STATUS, even in a "trap 0" or "set -e" context.
    as_fn_exit ()
    {
      set +e
      as_fn_set_status $1
    if echo $1 | egrep -q '^[0-9]+$'; then // $1 number check
      exit $1
    fi
    } # as_fn_exit
    #+END_SRC
  - if the following error occur when make install pipes:
    : impl/HadoopPipes.cc:1049:16: error: ‘sleep’ was not declared in this scope
    add #incldue "unistd.h" to src/c++/pipes/impl/HadoopPipes.cc
  
* compile & run
  #+BEGIN_SRC shell
  g++ wordcount-simple.cc -o wc -Iinstall/include -Linstall/lib -lhadooppipes  -lhadooputils -lpthread -lssl -lpthread -lcrypto
  hadoop fs -put wc bin
  hadoop pipes -Dhadoop.pipes.java.recordreader=true -Dhadoop.pipes.java.recordwriter=true -program wc -input in -output out
  #+END_SRC

* something
  - program xxx is same as -Dhadoop.pipes.executable=xxx
  - input/output is same as -Dmapred.input/output.dir

* reference
  - [[http://dongxicheng.org/mapreduce/hadoop-pipes-architecture/]]
  - [[http://cs.smith.edu/dftwiki/index.php/Hadoop_Tutorial_2.2_--_Running_C%2B%2B_Programs_on_Hadoop]]


