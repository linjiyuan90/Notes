
* proxyuser/impersonation functionality
* configuration
** stand alone
** pseudo cluster
   
   | core-site.xml                          | mapred-site.xml                   | hdfs-site.xml     |
   |----------------------------------------+-----------------------------------+-------------------|
   | fs.default.name=hdfs://localhost:8020/ | mapred.job.tracker=localhost:8021 | dfs.replication=1 |
   |                                        |                                   | dfs.name.dir=     |
   |                                        |                                   | dfs.data.dir=     |
   note:
   - if dfs.name/data.dir is not specified, it'll use
     /tmp/dfs/data,name, and this directory may be deleted after restart!
   - Remember to specify JAVA_HOME in conf/hadoop-env.sh

   : $ start-all.sh
   : $ jps
   : 26893 Jps
   : 26832 TaskTracker
   : 26620 SecondaryNameNode
   : 26333 NameNode
   : 26484 DataNode
   : 26703 JobTracker

** cluster
   conf/masters
   conf/slaves

* commands
  |       |   |
  |-------+---|
  | queue |   |
  | pipes |   |
  | jar   |   |

 - how to create a *superuser*
   - impersonation, doAs
   - The superuser must have *kerberos credentials* to be able to
     impersonate another user. 
 - Hadoop *proxyuser* capabilities

* how to do online update without lossing data/stopping service?
  
* sth
  - An =edge node= is a machine that has the Hadoop libraries installed
    , yet is not part of the actual cluster. It is for applications
    that have the ability to connect to the cluster and host ancillary
    services and end user applications which directly access the
    cluster.
  - ps aux | grep NameNode
  - how can hadoop create file in map.local.dir when using other
    user? The other user doesn't have write permission.
  - generic options should put before command specific options
    : new GenericOptionsParser(new Configuration(), args)).getRemainingArgs();
  - distributed cache will be shared by all mapper/reducer of a
    job. Files are automatically symlinked to mapper/reducer's
    working directory. User can rename, symlink it by using '#'
    : mydist_file#file1
    : mydist_file#file2
  - hostname can not have underscores

    
* mapred-default
  |                                             |                         default | desc                                                                                                                                                                                                                     |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.job.queue.name                       |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.mapper/reducer.class                 |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | *new api*                                   |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.mapper/reducer.new-api               |                      false/true |                                                                                                                                                                                                                          |
  | mapreduce.map/reduce.class                  |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | *memory configuration*                      |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.cluster.map/reduce.memory.mb         |                              -1 | *virtual memory*, of a single map/reduce *slot*. -1 means no limit                                                                                                                                                       |
  | mapred.cluster.max.map/reduce.memory.mb     |                              -1 | max memory a task tracker's child process (a mapper/reducer) can take.                                                                                                                                                   |
  | mapred.job.map/reduce.memory.mb             |                              -1 | size of vmem of a single map/reduce task (mapper/reducer), a job can ask for multiple slots for a single mapper/reducer, up to cluster.max.map.memory.mb. Only this can be set by a user, the above two are set by admin |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.tasktracker.map/reduce.tasks.maximum |                               2 | The maximum number of map/reduce tasks(slot) that will be run simultaneously by a task tracker.                                                                                                                          |
  | mapred.map/reduce.tasks                     |                               2 | The default number of map/reduce tasks per job. Ignored when mapred.job.tracker is "local".                                                                                                                              |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | *child process*                             |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.child.env                            |                                 | add environment variables for the tasker child  process, comma-separated                                                                                                                                                 |
  | mapred.child.java.opts                      |                        -Xmx200m | Java opts for the task tracker child processes.                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | *hdfs*                                      |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.min.split.size                       |                               0 |                                                                                                                                                                                                                          |
  | mapred.local.dir                            |  ${hadoop.tmp.dir}/mapred/local | local dir stores intermediate data files, comma-separated                                                                                                                                                                |
  | mapred.system.dir                           | ${hadoop.tmp.dir}/mapred/system | store control files                                                                                                                                                                                                      |
  | mapred.temp.dir                             |   ${hadoop.tmp.dir}/mapred/temp | distributed cache files are here?                                                                                                                                                                                        |
  |                                             |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | *task control*                              |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | mapred.map/reduce.max.attempts              |                               4 |                                                                                                                                                                                                                          |
  | mapred.skip.mode.enabled                    |                                 |                                                                                                                                                                                                                          |
  | mapred.skip.map.max.skip.records            |                               0 | The number of acceptable skip records surrounding the bad record PER bad record in mapper. 0 to turn off skip. Long.MAX_VALUE whatever get skipped are acceptable.                                                       |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | *hdfs*                                      |                                 |                                                                                                                                                                                                                          |
  |---------------------------------------------+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | fs.checkpoint.dir                           |                                 |                                                                                                                                                                                                                          |
  | dfs.name.dir                                |                                 |                                                                                                                                                                                                                          |

* web console
  |      | Daemon                  | Default Port | Configuration Parameter          |
  |------+-------------------------+--------------+----------------------------------|
  | HDFS | Namenode                |        50070 | dfs.http.address                 |
  |      | Datanodes               |        50075 | dfs.datanode.http.address        |
  |      | Secondarynamenode       |        50090 | dfs.secondary.http.address       |
  |      | Backup/Checkpoint node? |        50105 | dfs.backup.http.address          |
  |------+-------------------------+--------------+----------------------------------|
  | MR   | Jobracker               |        50030 | mapred.job.tracker.http.address  |
  |      | Tasktrackers            |        50060 | mapred.task.tracker.http.address |

* security
** SLA
  *Service Level Authorization* is the initial authorization mechanism
  to ensure clients connecting to a particular Hadoop service have the
  necessary, pre-configured, permissions and are authorized to access
  the given service. For example, a MapReduce cluster can use this
  mechanism to allow a configured list of users/groups to submit jobs.

  The ${HADOOP_CONF_DIR}/hadoop-policy.xml configuration file is used
  to define the access control lists for various Hadoop services.

  Service Level Authorization is performed much before to other access
  control checks such as file-permission checks, access control on job
  queues etc.
** ACL
   access control list

* api
** org.apache.hadoop.conf.Configuration
   : conf.set(key, value);
   : conf.setStrings(key, values);
