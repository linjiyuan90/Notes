  | url             | descritption      |
  |-----------------+-------------------|
  | localhost:50070 |                   |
  | localhost:50075 | hdfs file browser |
  

* security
** SLA
  *Service Level Authorization* is the initial authorization mechanism
  to ensure clients connecting to a particular Hadoop service have the
  necessary, pre-configured, permissions and are authorized to access
  the given service. For example, a MapReduce cluster can use this
  mechanism to allow a configured list of users/groups to submit jobs.

  The ${HADOOP_CONF_DIR}/hadoop-policy.xml configuration file is used
  to define the access control lists for various Hadoop services.

  Service Level Authorization is performed much before to other access
  control checks such as file-permission checks, access control on job
  queues etc.
** ACL
   access control list

* api
** org.apache.hadoop.conf.Configuration
   : conf.set(key, value);
   : conf.setStrings(key, values);
* jar
  To use generic options like =libjars=, need to make sure the code
  is using =GenericOptionsParser=
* access from edge node
  just change conf to cluster conf, same as hbase. Alternatives is to change
  HADOOP_CONF_DIR, HBASE_CONF_DIR. (Also, note the default conf is in
  $HADOOP_HOME/conf, $HBASE_HOME/conf)
** code
   just change the addResource to configuration
   : val hconf = new Configuraiton()
   : hconf.addResource("conf/hbase-site.xml")
   : hconf.addResource("conf/core-site.xml")
   : hconf.addResource("conf/mapred-site.xml")
   : val pool = new HTablePool(hconf, 10)
   Also, note that since the config files are located by resouce, need to add
   path to CLASSPATH (such as current working path '.', by default it exists)
* other
** tmp file
  It's better not put tmp(like pid) file in /tmp, since this may be removed by
  system.
